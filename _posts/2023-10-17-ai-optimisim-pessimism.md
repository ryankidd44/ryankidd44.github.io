---
layout: post
title: "AI x-safety optimisim vs. pessimism"
category: note
tags:
  - AI Safety
  - X
---

Reasons to be optimistic about AI x-safety:

1. The public cares more than expected;
2. Governments aren't ignoring the problem;
3. LMs might be much more interpretable than end-to-end RL;
4. Instructed LMs might generalize better than expected.

Reasons to be pessimistic about AI x-safety:

1. We might have less time than we thought;
2. The current best plan relies on big tech displaying a vastly better security mindset than usual;
3. There seems to be a shortage of new, good ideas for AI alignment;
4. A few actors (e.g., SBF) might have harmed the public image of orgs/movements pushing for AI x-safety.
