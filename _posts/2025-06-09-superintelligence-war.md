---
layout: post
title: "Superintelligence war"
category: note
tags:
  - AI Safety
  - Game Theory
  - X
---

War is very costly, particularly between superintelligences. If neither of two SIs has a decisive strategic advantage, they would likely cooperate, unless they cannot secure enforceable treaties or evidence that no DSA exists. An exception might be irreconcilable differences. Maybe we will see use cases for def/account technology like zero knowledge proofs that neither side has a DSA, without revealing their technology, or smart contacts that tie critical assets to "no first strike" policies?

I am still concerned about astronomically significant "inflection points", where massive value lock-in is possible, such as sending von Neumann probes with preprogrammed values to colonize soon-to-be-causally disconnected distant galaxies. Another inflection point might be the creation of the first superintelligence. [What sort of trades](https://slatestarcodex.com/2017/03/21/repost-the-demiurges-older-brother/) will it make with causally distant entities?
